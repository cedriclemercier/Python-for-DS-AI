{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the Gradient Boosting scratch code in our lecture such that:\n",
    "- Notice that we are still using max_depth = 1.  Attempt to tweak min_samples_split, max_depth for the regression and see whether we can achieve better mse on our boston data\n",
    "- Notice that we only write scratch code for gradient boosting for regression, add some code so that it also works for binary classification.  Load the breast cancer data from sklearn and see that it works.\n",
    "- Further change the code so that it works for multiclass classification.  Load the digits data from sklearn and see that it works\n",
    "- Put everything into class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoosting():\n",
    "    def __init__(self, regression = True, multiclass = False):\n",
    "        self.n_estimators = 200\n",
    "        self.tree_params = {'max_depth': 1, 'min_samples_split': 4}\n",
    "        self.models = [DecisionTreeRegressor(**self.tree_params) for _ in range(self.n_estimators)]\n",
    "        self.regression = regression\n",
    "        self.multiclass = multiclass\n",
    "    \n",
    "    def grad(self, y, h):\n",
    "        return y - h\n",
    "    \n",
    "    \n",
    "    def softmax(self, y_pred):\n",
    "        return np.exp(y_pred) / np.sum(np.exp(y_pred))\n",
    "    \n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        self.models_trained = []\n",
    "\n",
    "        #using DummyRegressor is a good technique for starting model\n",
    "        first_model = DummyRegressor(strategy='mean')\n",
    "        first_model.fit(X, y)\n",
    "        self.models_trained.append(first_model)\n",
    "\n",
    "        #fit the estimators\n",
    "        for i, model in enumerate(self.models):\n",
    "            #predict using all the weak learners we trained up to\n",
    "            #this point\n",
    "            y_pred = self.predict(X, last_predict = False)\n",
    "\n",
    "            #errors will be the total errors maded by models_trained\n",
    "            residual = self.grad(y, y_pred)\n",
    "\n",
    "            #fit the next model with residual\n",
    "            model.fit(X, residual)\n",
    "\n",
    "            self.models_trained.append(model)\n",
    "\n",
    "    def predict(self, X, last_predict = True):\n",
    "        learning_rate = 0.1  ##hard code for now\n",
    "        f0 = self.models_trained[0].predict(X)  #first use the dummy model\n",
    "        boosting = sum(learning_rate * model.predict(X) for model in self.models_trained[1:])\n",
    "        yhat = f0 + boosting\n",
    "        \n",
    "        # Logistic multinomial / binary part\n",
    "        if not self.regression:\n",
    "            yhat = self.softmax(yhat)\n",
    "            \n",
    "            # If we are doing predictions on the test set, return argmax on the col of probabilities\n",
    "            if last_predict:\n",
    "                yhat = np.argmax(yhat, axis = 1)\n",
    "                \n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our MSE:  12.945557601580582\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "gb = GradientBoosting(regression = True)\n",
    "\n",
    "X, y = load_boston(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "#fit the models\n",
    "models = gb.fit(X_train, y_train)\n",
    "\n",
    "#predict\n",
    "y_pred = gb.predict(X_test)\n",
    "\n",
    "#print metrics\n",
    "print(\"Our MSE: \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=green>Binary</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0]\n"
     ]
    }
   ],
   "source": [
    "data_breast = load_breast_cancer()\n",
    "X2 = data_breast.data\n",
    "y2 = data_breast.target\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, \n",
    "                                                    test_size=0.3, random_state=42)\n",
    "m, n = X2.shape\n",
    "k = len(set(y2_train))\n",
    "y_train_encoded = np.zeros((X2_train.shape[0], k))\n",
    "for each_class in range(k):\n",
    "    cond = y2_train == each_class\n",
    "    y_train_encoded[np.where(cond), each_class] = 1\n",
    "    \n",
    "gb_logistic = GradientBoosting(regression = False)\n",
    "breast_models = gb_logistic.fit(X2_train, y_train_encoded)\n",
    "\n",
    "y_pred2 = gb_logistic.predict(X2_test)\n",
    "print(y_pred2[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our accuracy:  0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "#print metrics\n",
    "print(\"Our accuracy: \", accuracy_score(y2_test, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=green>Multinomial</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64) (1797,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "data_digits = load_digits()\n",
    "X3 = data_digits.data\n",
    "y3 = data_digits.target\n",
    "\n",
    "print(X3.shape, y3.shape)\n",
    "# Note: 1797 samples, 64 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, \n",
    "                                                    test_size=0.3, random_state=42)\n",
    "\n",
    "m, n = X3.shape\n",
    "k = len(set(y3_train))\n",
    "y3_train_encoded = np.zeros((X3_train.shape[0], k))\n",
    "for each_class in range(k):\n",
    "    cond = y3_train == each_class\n",
    "    y3_train_encoded[np.where(cond), each_class] = 1\n",
    "    \n",
    "gb_logistic = GradientBoosting(regression = False)\n",
    "breast_models = gb_logistic.fit(X3_train, y3_train_encoded)\n",
    "\n",
    "y_pred3 = gb_logistic.predict(X3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our accuracy:  0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "#print metrics\n",
    "print(\"Our accuracy: \", accuracy_score(y2_test, y_pred2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
